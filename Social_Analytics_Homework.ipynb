{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import json\n",
    "import numpy as np\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up API keys and authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#API Keys for owner yydata_PlotBot\n",
    "consumer_key = \"6dj1rPeIXm9lGHAJ0XDOlBCKT\"\n",
    "consumer_secret = \"Czsnhwgan8wDkShkWclER9XNcpurhJFWmCBaC5EvVv5BcKPhHV\"\n",
    "access_token = \"968998318780174336-zgI9bmi7Oaf3FbpeaIP6SxpFN85LewW\"\n",
    "access_token_secret =\"kttUSYIn0NmynHBswVRehSC0BBV2akgqk4hfQ6i5VlFK7\"\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)#,parser=tweepy.parsers.JSONParser())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plotbot function:\n",
    " receive tweet to '@yydata_PlotBot' for a sentimental analysis record and tweet back the requester the analysis graph \n",
    " When you run the script,please try:\n",
    " Tweet me Analyze:id/name/screen name for sentimental score analysis\n",
    " \n",
    " Note: 1. No tweet will be sent if the requested search target has been searched before\n",
    "       2. id/name/screen name to analyze needs to be put in the format Analyze:id/name/screen (must be after ':') \n",
    "       3. all searches have been done are updated and output to a request_log.csv\n",
    "\n",
    "# plotbot function:\n",
    " receive tweet to '@yydata_PlotBot' for a sentimental analysis record and tweet back the requester the analysis graph \n",
    " When you run the script,please try:\n",
    " Tweet me Analyze:id/name/screen name for sentimental score analysis\n",
    " \n",
    " Note: 1. No tweet will be sent if the requested search target has been searched before\n",
    "       2. id/name/screen name to analyze needs to be put in the format Analyze:id/name/screen (must be after ':') \n",
    "       3. all searches have been done are updated and output to a request_log.csv\n",
    "\n",
    "To Baron or Seth:\n",
    "    I '@yizhiyin' sent '@yydata_PlotBot' several tweet requests for plotting and got the expected response. Then I changed the scripts a bit, put it on Heroku and ran for sometime. It was fine at begining(it succesfully responded to the request to search '@Chinamission2run' and then it started to give me multiple images on one plot (I am wondering if this has anything to do with the fact that I have to change 'import matplotlib matplotlib.use('Agg')' to build it on heroku ). Then I found out that my account '@yydata_PlotBot' could not receive any more tweets. No matter who tweets me at that account after the tweet id=970742808272351233, it will never show up on api.search(q='@yydata_PlotBot'), nor can I see it on notification tab on the twitter website either. I wonder if this account is blocked as a robot by twitter. If you tweet me and run the script, it will print:no new tweet since last search 970742808272351233. I tried with new api key and token, but still no luck in receiving new tweets. I also tried to create another twitter account @yyplotbot using a different email address, but still cannot retrieve anything using api.search . I feel like that I have spent too much time on this. But it did work with '@yydata_PlotBot' when I tested earlier, you can check the corresponding tweets at https://twitter.com/yydata_PlotBot?lang=en. \n",
    "   Also the Output directory has the png response that it has succesfuly responded as I was testing at my desktop at the very beginning. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotbot():\n",
    "    #read saved search_record into pd.dataframe\n",
    "    search_record=pd.read_csv('request_log.csv')\n",
    "\n",
    "    #find the most recent tweet_id in the search_record and assign it as the max_id \n",
    "    max_id=search_record['tweet_id'].max()\n",
    "\n",
    "    #plobot_id(my bot screen name)\n",
    "    plotbot_id='@yydata_PlotBot'\n",
    "\n",
    "    #retrive new tweets every since the most recent tweet_id\n",
    "    tweets_to_me =tweepy.Cursor(api.search,q=plotbot_id,result_type=\"recent\",lang='en',since_id=max_id).items()\n",
    "\n",
    "    #use a list to store tweet_text,tweet_id, and sn_requester (the screen name of the requester)\n",
    "    tweet_text=[]\n",
    "    tweet_id=[]\n",
    "    sn_requester=[] \n",
    "\n",
    "    #extract tweet_text, tweet_id and screen name of the requester\n",
    "    for tweet in tweets_to_me:\n",
    "        tweet_text.append(tweet.text)\n",
    "        tweet_id.append(tweet.id)\n",
    "        sn_requester.append(tweet.user.screen_name)\n",
    "        #if no more updates, tweet_id list will be empty []\n",
    "        #if there are updates,tweet_id list will not be empty\n",
    "\n",
    "    #extract all the targets that have been searched out from the record dataframe as a list \n",
    "    searched_list=search_record['search_target'].values.tolist()\n",
    "\n",
    "    #initiate new_rows which will be added to the record dataframe\n",
    "    new_rows=[]\n",
    "\n",
    "    #if there are new tweets(if there is no new tweet eversince last search tweet_text,tweet_id, sn_requester will still\n",
    "    #be an empty list)\n",
    "    if bool(tweet_id)==True:\n",
    "        \n",
    "        #Code below is to a:extract the search target from the tweet_text\n",
    "                        # b:decide if the search target that has not been searched before\n",
    "            #             c:save the new search target information as a new dataframe\n",
    "            #             d: append the new dataframe to the search record and output the updated search_record as csv\n",
    "        \n",
    "    \n",
    "        #use a while loop to extract the info of new search target\n",
    "        #start a counter\n",
    "        i=0\n",
    "        while i < len(tweet_text):\n",
    "        #extract strings after ':'.eg. '@yydata_PlotBot Analyze:id/name/screen_name' get the 'id/name/screen_name'\n",
    "        #only proceed when the following conditions are met\n",
    "            #a.being able to extract id/name/screen_name\n",
    "            #b.this id/name/screen_name have not been searched before\n",
    "            if (bool(re.findall(r'(?<=:)[@\\w]+', tweet_text[i]))==True and re.findall(r'(?<=:)[@\\w]+', tweet_text[i])[0]\\\n",
    "                not in searched_list):\n",
    "#                 print('the current searched_list is {}'.format(searched_list))\n",
    "#                 print('we have a unique target {}'.format(tweet_text[i]))\n",
    "                \n",
    "                # re.findall returns a list;\n",
    "                #for this case only one element is in list(unless someone tweet me two names in one tweet, then I am only\n",
    "                #going to analyze the first one)\n",
    "                search_target=re.findall(r'(?<=:)[@\\w]+', tweet_text[i])[0]\n",
    "#                 print(search_target)\n",
    "                \n",
    "                #extract corresponding screen_name, tweet_id of the new search_target\n",
    "                new_sn=sn_requester[i]\n",
    "#                 print(new_sn)\n",
    "                new_tweet_id=tweet_id[i]\n",
    "#                 print(new_tweet_id)\n",
    "                #append all the info of the new search_target into new_rows(so I can make new dataframe and append to the\n",
    "                #search record)\n",
    "                new_rows.append([search_target,new_sn,new_tweet_id])\n",
    "#                 print('new_rows is {}\\n'.format(new_rows))\n",
    "                \n",
    "                #append this new target to the searched_list \n",
    "                searched_list.append(search_target)\n",
    "#                 print('current searched_list is {}'.format(searched_list))\n",
    "                \n",
    "            else:\n",
    "                print('No id is found or i have searched this before {}'.format(tweet_text[i]))\n",
    "            i+=1\n",
    "        #check if there are any new valid targets if there are new_rows=[[search_target,new_sn,new_tweet_id],,,]\n",
    "        #if no new valid target name has been retrieved  new_rows=[[]] \n",
    "        if new_rows!=[[]]:\n",
    "            #make a new_df if there are new targets and append it to the search_record\n",
    "            new_df=pd.DataFrame(new_rows,columns=['search_target','sn_requester','tweet_id'])\n",
    "#             print('new_df is {}'.format(new_df))\n",
    "            search_record=search_record.append(new_df, ignore_index=True)\n",
    "#             print('current search_record is {}'.format(search_record))\n",
    "            \n",
    "            #Save the updated search onto the request_log.csv\n",
    "            search_record.to_csv('request_log.csv',index=False)\n",
    "            \n",
    "            #code below is to plot and update\n",
    "            analyzer = SentimentIntensityAnalyzer()\n",
    "            \n",
    "            #define a variable to store # of tweets to retrieve\n",
    "            max_item=500\n",
    "            for i in new_df['search_target'].values.tolist():\n",
    "                try:\n",
    "#                 print(i)\n",
    "                    target_tweets=tweepy.Cursor(api.user_timeline,id=i,result_type=\"recent\").items(max_item)\n",
    "                    tweets_list=[tweet.text for tweet in target_tweets]\n",
    "                    compound = [analyzer.polarity_scores(i)[\"compound\"] for i in tweets_list]\n",
    "                    sentiment, =plt.plot(np.arange(0,len(compound),1),compound,marker=\"o\", linewidth=0.5, alpha=0.8,label=i)\n",
    "                    # # Incorporate the other graph properties\n",
    "                    plt.title(\"Sentiment Analysis of Tweets (%s) for %s\" % (time.strftime(\"%x\"), i))\n",
    "                    plt.ylabel(\"Tweet Polarity\")\n",
    "                    plt.xlabel(\"Tweets Ago\")\n",
    "                    plt.legend(handles=[sentiment], loc=\"best\")\n",
    "                    filepath='output/'+i+'.png'\n",
    "                    plt.savefig(filepath)\n",
    "                    plt.show()\n",
    "                    #code below is to update the information to the requester\n",
    "                    respond_id=new_df.loc[new_df[\"search_target\"] == i, \"tweet_id\"].values[0]\n",
    "                    respond_sn=new_df.loc[new_df[\"search_target\"] ==i ,'sn_requester'].values[0]\n",
    "                    api.update_with_media(filepath,\"thanks @{} for your request\".format(respond_sn),in_reply_to_status_id = respond_id)\n",
    "                    print('New graph has been sent') \n",
    "                except tweepy.TweepError as e:\n",
    "                    print(e)\n",
    "                    pass\n",
    "        \n",
    "        else:\n",
    "            print('no new valid id has been retrieved ever since last search {}'.format(max_id))\n",
    "        \n",
    "    else:\n",
    "        print('no new tweet since last search {}'.format(max_id))\n",
    "                #see if the target has been searched already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now run the script for 15 minuts \n",
    "#I do not like to run an infinite loop unless I am running the script on some server\n",
    "counter=0\n",
    "while counter<5:\n",
    "    plotbot()\n",
    "    print('I have ran {} times'.format(counter))\n",
    "    counter+=1\n",
    "    time.sleep(300)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
